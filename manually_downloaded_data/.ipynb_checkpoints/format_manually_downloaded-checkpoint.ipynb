{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. What's that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After getting the data from Market Watch, the indexes have to be preprocessed to format available to train by Temporal Fusion Transformers.\n",
    "\n",
    "In this script the datasets are:\n",
    "\n",
    "a) Loaded\n",
    "\n",
    "b) Preprocessed & merged\n",
    "\n",
    "c) Visualized\n",
    "\n",
    "d) Summarized\n",
    "\n",
    "e) Enriched with date-related categories\n",
    "\n",
    "f) Written to the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import missingno\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_names = [\"SP500\", \"Gold\", \"EURUSD\"]\n",
    "datasets_n = len(datasets_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [None] * datasets_n\n",
    "for dt_idx, dt_name in enumerate(datasets_names):\n",
    "    datasets[dt_idx] = pd.DataFrame(columns=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\"])\n",
    "    for csv_no in range(10):\n",
    "        datasets[dt_idx] = pd.concat([datasets[dt_idx], pd.read_csv(dt_name + \"/\" + str(csv_no+1) + '.csv',\n",
    "                                                        thousands=',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[1].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preprocessing & merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_analyzed = pd.date_range(start='2012-04-02', end='2022-04-01') # no data for SP500 before 2013-04-02\n",
    "dates_analyzed = pd.DataFrame(dates_analyzed, columns=[\"Date\"])\n",
    "dates_analyzed[\"Date\"] = dates_analyzed[\"Date\"].dt.strftime('%m/%d/%Y')\n",
    "dates_analyzed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [dates_analyzed.merge(datasets[i], on=\"Date\", how=\"left\") for i in range(datasets_n)]\n",
    "datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_merged = pd.concat([datasets[i] for i in range(datasets_n)], axis=1)\n",
    "datasets_merged = datasets_merged.T.drop_duplicates().T\n",
    "column_names = [\"Open\", \"High\", \"Low\", \"Close\"]\n",
    "merged_column_names_tmp = [col_name + \"_\" + datasets_names[i] for i in range(datasets_n) for col_name in column_names]\n",
    "merged_column_names = [\"Date\"]\n",
    "merged_column_names.extend(merged_column_names_tmp)\n",
    "datasets_merged.columns = merged_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_merged[\"Date\"] = pd.to_datetime(datasets_merged['Date'], errors='coerce')\n",
    "datasets_merged[\"Date\"] = pd.to_datetime(datasets_merged['Date'].dt.strftime('%Y/%m/%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in datasets_merged.columns:\n",
    "    if col != \"Date\":\n",
    "        datasets_merged[col] = datasets_merged[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_merged.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in datasets_names:\n",
    "    x = datasets_merged[\"Date\"]\n",
    "    y = copy.deepcopy(datasets_merged[\"Open_\" + dataset_name])\n",
    "    label = dataset_name\n",
    "    if dataset_name == \"EURUSD\":\n",
    "        y *= 2500\n",
    "        label += (\" * 2500\")\n",
    "    plt.plot(x, y, label=label)\n",
    "plt.title(\"Considered index values in subsequent years\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Index value\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = datasets_merged.drop(\"Date\", axis=1)\n",
    "correlation_matrix = correlation_matrix[[\"Open_SP500\", \"Open_Gold\", \"Open_EURUSD\"]].corr()\n",
    "sn.heatmap(correlation_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_merged.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missingno.matrix(datasets_merged, figsize=(10,5), fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Extra time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_dimension = pd.read_csv(\"date_dimension.csv\", sep=';').drop(\"Date\", axis=1)\n",
    "date_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_merged = pd.concat([datasets_merged, date_dimension], axis=1)\n",
    "datasets_merged.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. CSV file write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_merged.to_csv(\"../data/economy/economy_manual.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
